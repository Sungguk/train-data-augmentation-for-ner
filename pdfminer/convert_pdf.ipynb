{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/39854841/pdfminer-python-3-5/40877143#40877143\n",
    "# from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# from pdfminer.converter import HTMLConverter,TextConverter,XMLConverter\n",
    "# from pdfminer.layout import LAParams\n",
    "# from pdfminer.pdfpage import PDFPage\n",
    "# import io\n",
    "\n",
    "# def convert(case,fname, pages=None):\n",
    "#     if not pages: \n",
    "#         pagenums = set();\n",
    "#     else:\n",
    "#         pagenums = set(pages);      \n",
    "#     manager = PDFResourceManager() \n",
    "#     codec = 'utf-8'\n",
    "#     caching = True\n",
    "\n",
    "#     if case == 'text' :\n",
    "#         output = io.StringIO()\n",
    "#         converter = TextConverter(manager, output, codec=codec, laparams=LAParams())     \n",
    "#     if case == 'HTML' :\n",
    "#         output = io.BytesIO()\n",
    "#         converter = HTMLConverter(manager, output, codec=codec, laparams=LAParams())\n",
    "\n",
    "#     interpreter = PDFPageInterpreter(manager, converter)   \n",
    "#     infile = open(fname, 'rb')\n",
    "\n",
    "#     for page in PDFPage.get_pages(infile, pagenums,caching=caching, check_extractable=True):\n",
    "#         interpreter.process_page(page)\n",
    "\n",
    "#     convertedPDF = output.getvalue()  \n",
    "\n",
    "#     infile.close(); converter.close(); output.close()\n",
    "#     return convertedPDF\n",
    "\n",
    "# #//////////// main ///////////////////////\n",
    "# filePDF  = 'myDir//Oxford Collocation Dictionary.pdf'     # input\n",
    "# fileHTML = 'myDir//Oxford Collocation Dictionary.html'   # output\n",
    "# fileTXT  = 'myDir//Oxford Collocation Dictionary.txt'     # output\n",
    "\n",
    "# case = \"text\"\n",
    "\n",
    "# if case == 'HTML' :\n",
    "#     convertedPDF = convert('HTML', filePDF, pages=[0,100])\n",
    "#     fileConverted = open(fileHTML, \"wb\")\n",
    "# if case == 'text' :\n",
    "#     convertedPDF = convert('text', filePDF, pages=[0,100])\n",
    "#     fileConverted = open(fileTXT, \"w\")\n",
    "\n",
    "# fileConverted.write(convertedPDF)\n",
    "# fileConverted.close()\n",
    "# #print(convertedPDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200508"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "\n",
    "    pagenos = set();\n",
    "  \n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "    return text\n",
    "\n",
    "text_form = convert_pdf_to_txt('myDir//Oxford Collocation Dictionary.pdf')\n",
    "print(len(text_form))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm\\n\\nOXFORD Collocations | dictionary for students of English\\n\\n●     A level noun\\n●     abandon verb\\n●     abashed adj\\n●     abbreviation noun\\n●     abhorrent adj\\n●     ability noun\\n●     ablaze adj\\n●     able adj\\n●     abode noun\\n●     abolish verb\\n●     abortion noun\\n●     abscess noun\\n●     absence noun\\n●     absent adj\\n●     absorb verb\\n●     absorbed adj\\n●     abstract adj\\n●     absurd adj\\n●     abundance noun\\n●     abuse noun\\n●     abuse verb\\n●     abusive adj\\n●     academic adj\\n●     academy noun\\n●     accelerate verb\\n●     acceleration noun\\n●     accelerator noun\\n●     accent noun\\n●     accept verb\\n●     acceptable adj\\n●     acceptance noun\\n●     access noun\\n●     accessible adj\\n●     accessory noun\\n●     accident noun\\n●     accidental adj\\n\\nfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm (1 of 222) [8/26/2009 1:06:28 pm]\\n\\n\\x0cfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm\\n\\n●     acclaim noun\\n●     acclaim verb\\n●     accolade noun\\n●     accommodate verb\\n●     accommodation noun\\n●     accompaniment noun\\n●     accomplice noun\\n●     accomplish verb\\n●     accomplished adj\\n●     accomplishment noun\\n●     accord noun\\n●     accord verb\\n●     account noun\\n●     account verb\\n●     accountability noun\\n●     accountable adj\\n●     accountancy noun\\n●     accountant noun\\n●     accumulate verb\\n●     accumulation noun\\n●     accuracy noun\\n●     accurate adj\\n●     accusation noun\\n●     accuse verb\\n●     accustomed adj\\n●     ace noun\\n●     ache noun\\n●     ache verb\\n●     achieve verb\\n●     achievement noun\\n●     acid noun\\n●     acknowledge verb\\n●     acknowledgement noun\\n●     acne noun\\n●     acquaintance noun\\n●     acquainted adj\\n●     acquisition noun\\n●     acquittal noun\\n\\nfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm (2 of 222) [8/26/2009 1:06:28 pm]\\n\\n\\x0cfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm\\n\\n●     acre noun\\n●     act noun\\n●     act verb\\n●     acting noun\\n●     action noun\\n●     active adj\\n●     activity noun\\n●     actor noun\\n●     actress noun\\n●     acumen noun\\n●     acupuncture noun\\n●     ad noun\\n●     adapt verb\\n●     adaptable adj\\n●     adaptation noun\\n●     add verb\\n●     addict noun\\n●     addicted adj\\n●     addiction noun\\n●     addictive adj\\n●     addition noun\\n●     address noun\\n●     address verb\\n●     adept adj\\n●     adequate adj\\n●     adhere verb\\n●     adherence noun\\n●     adjacent adj\\n●     adjective noun\\n●     adjourn verb\\n●     adjust verb\\n●     adjustable adj\\n●     adjustment noun\\n●     administer verb\\n●     administration noun\\n●     admirable adj\\n●     admiral noun\\n●     admiration noun\\n\\nfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm (3 of 222) [8/26/2009 1:06:28 pm]\\n\\n\\x0cfile:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/index.htm\\n\\n●     admire verb\\n●     admirer noun\\n●     admission noun\\n●     admit verb\\n●     admittance noun\\n●     adolescence noun\\n●     adolescent noun\\n●     adopt verb\\n●     adoption noun'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(text_form))\n",
    "(text_form[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_noise(list_splited_data):\n",
    "    open_= False\n",
    "    close_= False\n",
    "    \n",
    "    for char in list_splited_data:\n",
    "        if char == '[':\n",
    "            open_= True\n",
    "        elif char == ']':\n",
    "            close_= True\n",
    "    \n",
    "    if open_== True and close_== True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splited_data = text_form.split('file:///C|/TEMP/htm/OXFORD_PHRASEBUILDER_HTML/files/')\n",
    "splited_data.remove('')\n",
    "filtered_data = [row for row in splited_data if check_noise(list(row))==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index.htm\\n\\nOXFORD Collocations | dictionary for students of English\\n\\n●     A level noun\\n●     abandon verb\\n●     abashed adj\\n●     abbreviation noun\\n●     abhorrent adj\\n●     ability noun\\n●     ablaze adj\\n●     able adj\\n●     abode noun\\n●     abolish verb\\n●     abortion noun\\n●     abscess noun\\n●     absence noun\\n●     absent adj\\n●     absorb verb\\n●     absorbed adj\\n●     abstract adj\\n●     absurd adj\\n●     abundance noun\\n●     abuse noun\\n●     abuse verb\\n●     abusive adj\\n●     academic adj\\n●     academy noun\\n●     accelerate verb\\n●     acceleration noun\\n●     accelerator noun\\n●     accent noun\\n●     accept verb\\n●     acceptable adj\\n●     acceptance noun\\n●     access noun\\n●     accessible adj\\n●     accessory noun\\n●     accident noun\\n●     accidental adj\\n\\n',\n",
       " 'index.htm\\n\\n●     acclaim noun\\n●     acclaim verb\\n●     accolade noun\\n●     accommodate verb\\n●     accommodation noun\\n●     accompaniment noun\\n●     accomplice noun\\n●     accomplish verb\\n●     accomplished adj\\n●     accomplishment noun\\n●     accord noun\\n●     accord verb\\n●     account noun\\n●     account verb\\n●     accountability noun\\n●     accountable adj\\n●     accountancy noun\\n●     accountant noun\\n●     accumulate verb\\n●     accumulation noun\\n●     accuracy noun\\n●     accurate adj\\n●     accusation noun\\n●     accuse verb\\n●     accustomed adj\\n●     ace noun\\n●     ache noun\\n●     ache verb\\n●     achieve verb\\n●     achievement noun\\n●     acid noun\\n●     acknowledge verb\\n●     acknowledgement noun\\n●     acne noun\\n●     acquaintance noun\\n●     acquainted adj\\n●     acquisition noun\\n●     acquittal noun\\n\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8380"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_data = [row for row in splited_data if row[0:5]=='index']\n",
    "pos = ['noun', 'adj', 'verb']\n",
    "voca = []\n",
    "for row in index_data:\n",
    "    pair_list = row.split('●')\n",
    "    if len(pair_list)!=1: # noise filtering\n",
    "        for pair in pair_list:\n",
    "            if pair.split()[-1] in pos:\n",
    "                voca.append((pair.split()[-2], pair.split()[-1]))\n",
    "len(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('level', 'noun'),\n",
       " ('abandon', 'verb'),\n",
       " ('abashed', 'adj'),\n",
       " ('abbreviation', 'noun'),\n",
       " ('abhorrent', 'adj'),\n",
       " ('ability', 'noun'),\n",
       " ('ablaze', 'adj'),\n",
       " ('able', 'adj'),\n",
       " ('abode', 'noun'),\n",
       " ('abolish', 'verb')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voca[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Voca's friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "friend_list = [0] * len(voca)\n",
    "nonindex_data = [row for row in splited_data if row[0:5]!='index']\n",
    "noise_str_list = ['OXFORD Collocations | dictionary for students of English', '\\x0c']\n",
    "\n",
    "for row in nonindex_data:\n",
    "    \n",
    "    # filter   \n",
    "    filtered_list = row.split('\\n')\n",
    "    \n",
    "    # noise row pass\n",
    "    if filtered_list[-1] == '\\x0c':\n",
    "        continue\n",
    "    \n",
    "    # 우리가 원하는 List filtering\n",
    "    if filtered_list[2] == 'OXFORD Collocations | dictionary for students of English':\n",
    "        \n",
    "        ### get info \n",
    "        word_pos = tuple(filtered_list[0].split('.')[0].split('_'))\n",
    "        try:voca_index = voca.index(word_pos)\n",
    "        except(ValueError):continue\n",
    "        \n",
    "        ### better distinguish\n",
    "        token_list = ' '.join(filtered_list[6:]).replace(',',' ,').split()\n",
    "        \n",
    "        ### add friend info\n",
    "        if word_pos[1] == 'noun':\n",
    "            # initialization\n",
    "            tkn, pre_token, temp = False, 'none', []\n",
    "            for i, each in enumerate(token_list):   \n",
    "                # tkn 활성화 여부 결정\n",
    "                if tkn == True and each.isupper() == True: # ADJ.를 지나고, 그 다음 VERB 또는 PHRASES를 만났을 때.\n",
    "                    if len(list(each)) != 1:\n",
    "                        tkn = False\n",
    "                if each == 'ADJ.': # 위치 주의.\n",
    "                    tkn = True                    \n",
    "                    \n",
    "                # 형용사 저장 (명사니까..)\n",
    "                if tkn == True:\n",
    "                    if pre_token == 'ADJ.' or pre_token == ',' or pre_token == '|':\n",
    "                        temp.append(each)\n",
    "                # pre_token 저장\n",
    "                pre_token = each # 위치 주의.\n",
    "                \n",
    "\n",
    "        elif word_pos[1] == 'verb':\n",
    "            # initialization\n",
    "            tkn, pre_token, temp = False, 'none', []\n",
    "            for i, each in enumerate(token_list):   \n",
    "                # tkn 활성화 여부 결정\n",
    "                if tkn == True and each.isupper() == True: # ADJ.를 지나고, 그 다음 VERB 또는 PHRASES를 만났을 때.\n",
    "                    if len(list(each)) != 1:\n",
    "                        tkn = False\n",
    "                if each == 'ADV.': # 위치 주의.\n",
    "                    tkn = True                    \n",
    "                # 형용사 저장 (명사니까..)\n",
    "                if tkn == True:\n",
    "                    if pre_token == 'ADV.' or pre_token == ',' or pre_token == '|':\n",
    "                        temp.append(each)\n",
    "                # pre_token 저장\n",
    "                pre_token = each # 위치 주의.\n",
    "\n",
    "\n",
    "        elif word_pos[1] == 'adj':\n",
    "            # initialization\n",
    "            tkn, pre_token, temp = False, 'none', []\n",
    "            for i, each in enumerate(token_list):   \n",
    "                # tkn 활성화 여부 결정\n",
    "                if tkn == True and each.isupper() == True: # ADJ.를 지나고, 그 다음 VERB 또는 PHRASES를 만났을 때.\n",
    "                    if len(list(each)) != 1:\n",
    "                        tkn = False\n",
    "                if each == 'ADV.': # 위치 주의.\n",
    "                    tkn = True                    \n",
    "                # 형용사 저장 (명사니까..)\n",
    "                if tkn == True:\n",
    "                    if pre_token == 'ADV.' or pre_token == ',' or pre_token == '|':\n",
    "                        temp.append(each)\n",
    "                # pre_token 저장\n",
    "                pre_token = each # 위치 주의.            \n",
    "        \n",
    "        # delete redundant tokens\n",
    "        if 'a' in temp: temp.remove('a')\n",
    "        if 'etc.' in temp: temp.remove('etc.')\n",
    "    \n",
    "        # add \n",
    "        friend_list[voca_index] = temp\n",
    "    \n",
    "    \n",
    "    # print\n",
    "#     if tkn == False:\n",
    "#         print(filtered_list)\n",
    "#         print('\\n')\n",
    "\n",
    "# 할당되지 않은 애들 빈 리스트로 초기화\n",
    "for i, each in enumerate(friend_list):\n",
    "    if each==0:\n",
    "        friend_list[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('level', 'noun')\n",
      "['high', 'record', 'significant', 'substantial', 'increasing', 'rising', 'excessive', 'low', 'decreasing', 'falling', 'varying', 'with', 'generous', 'permitted', 'recommended', 'required', 'acceptable', 'adequate', 'necessary', 'normal', 'realistic', 'reasonable', 'safe', 'dangerous', 'unacceptable', 'worst', 'noise', 'pollution', 'radiation', 'crime', 'blood-sugar', 'cholesterol', 'hormone', 'stress', 'basic', 'elementary', 'low', 'entry', 'intermediate', 'advanced', 'high', 'degree', 'difficulty', 'fitness']\n",
      "\n",
      "\n",
      "('abandon', 'verb')\n",
      "['hastily', 'altogether', 'completely', 'entirely', 'totally', 'effectively', 'largely', 'virtually', 'simply', 'formally', 'quickly', 'quietly', 'temporarily', 'voluntarily']\n",
      "\n",
      "\n",
      "('abashed', 'adj')\n",
      "['slightly', 'suitably']\n",
      "\n",
      "\n",
      "('abbreviation', 'noun')\n",
      "['common', 'standard']\n",
      "\n",
      "\n",
      "('abhorrent', 'adj')\n",
      "['totally', 'utterly']\n",
      "\n",
      "\n",
      "('ability', 'noun')\n",
      "['exceptional', 'extraordinary', 'great', 'outstanding', 'remarkable', 'uncanny', 'inherent', 'innate', 'natural', 'proven', 'academic', 'acting', 'artistic', 'athletic', 'creative', 'intellectual', 'linguistic', 'mathematical', 'musical', 'reading', 'technical', 'mental', 'physical', 'high', 'limited', 'low', 'average', 'mixed']\n",
      "\n",
      "\n",
      "('ablaze', 'adj')\n",
      "['well']\n",
      "\n",
      "\n",
      "('able', 'adj')\n",
      "['perfectly', 'quite', 'well', 'better', 'more', 'just', 'barely', 'hardly', 'only', 'scarcely', 'less', 'extremely', 'very', 'fairly', 'reasonably']\n",
      "\n",
      "\n",
      "('abode', 'noun')\n",
      "['humble']\n",
      "\n",
      "\n",
      "('abolish', 'verb')\n",
      "['altogether', 'completely', 'totally', 'virtually', 'largely']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "cnt = 0\n",
    "for i, pair in enumerate(voca):\n",
    "    \n",
    "    print(voca[i])\n",
    "    print(friend_list[i])\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    cnt +=1\n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save(data, name):\n",
    "    filehandler = open(name,\"wb\")\n",
    "    pickle.dump(data, filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(voca, 'voca')\n",
    "save(friend_list, 'friend_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 문제점 1\n",
    "# ADJ. precipitous, severe, sheer, steep | gentle, gradual, slight | long, short |\n",
    "# downhill, downward | uphill, upward | higher, upper There was snow on the\n",
    "# higher slopes of the mountain. | lower | northern, north-facing, etc. The\n",
    "# vineyards on the south-facing slopes get more sunshine. | open | forested, grassy,\n",
    "# icy, rocky, scree, smooth, snow-covered/snowy, wooded | mountain | dry,\n",
    "# nursery, ski dry-slope skiing Some tourists were having a skiing lesson on the\n",
    "# nursery slope. | negative, positive The unemployment-income curve on the graph\n",
    "# has a negative slope. | slippery (figurative) Once he'd tried that first cigarette, he\n",
    "# was on the slippery slope to being a smoker.\n",
    "\n",
    "# 여기서 he가 포함된다. 앞에 , 콤마가 있기 때문이다\n",
    "# 이처럼 만약에 예문 중에 콤마가 있으면 그 다음 단어도 포함된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
